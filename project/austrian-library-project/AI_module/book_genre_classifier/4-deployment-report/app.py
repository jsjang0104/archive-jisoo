import gradio as gr
import os
import torch
import torch.nn.functional as F
import numpy as np
import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# ==============================================================================
# [1] ëª¨ë¸
# ==============================================================================

# ------------------------------------------------------------------------------
# í•˜ì´í¼íŒŒë¼ë¯¸í„°, ê²½ë¡œ ì„¤ì •
# ------------------------------------------------------------------------------
HF_MODEL_ID = "jsjang0104/book-genre-classifier-bert"
LABELS = [
    "Geschichte",
    "Literatur",
    "Sozialwissenschaften",
    "Sprachwissenschaft",
]  # CLASS_NAMES
NUM_CLASSES = len(LABELS)
MAX_LEN = 256  # training.ipynbì™€ ë™ì¼
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ê²½ë¡œ ì„¤ì • ì™„ë£Œ")

print("--- 1. ëª¨ë¸ ë¡œë“œ ì‹œì‘ ---")
try:
    # í† í¬ë‚˜ì´ì € ë¡œë“œ
    tokenizer = AutoTokenizer.from_pretrained(HF_MODEL_ID)

    # ê°€ì¤‘ì¹˜ íŒŒì¼ ë¡œë“œ ë° ëª¨ë¸ ë³µì›
    model = AutoModelForSequenceClassification.from_pretrained(
        HF_MODEL_ID, num_labels=NUM_CLASSES, trust_remote_code=True
    )
    model.to(device)
    model.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •

    print(f"âœ… ëª¨ë¸ '{HF_MODEL_ID}' ë¡œë“œ ì™„ë£Œ (Device: {device})")

except Exception as e:
    print(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    print("GitHub/Hugging Face ID ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    print(f" [ì—ëŸ¬ í•´ê²° ì•ˆë‚´]")
    print(
        f"   - **ì›ì¸:** Hugging Faceì˜ ìµœì‹  ê°€ì¤‘ì¹˜ íŒŒì¼ í˜•ì‹ì¸ 'model.safetensors'ë¥¼ ë¡œë“œí•˜ëŠ” ë° í•„ìš”í•œ "
    )
    print(f"     ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë¡œì»¬ í™˜ê²½ì— ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    print(
        f"   - **í•´ê²° ë°©ë²• (ê°€ì¥ ìœ ë ¥):** í„°ë¯¸ë„/í”„ë¡¬í”„íŠ¸ì—ì„œ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ 'safetensors' ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”."
    )
    print(f"     >>> pip install safetensors")
    print(
        f"   - **ì¶”ê°€ í•´ê²° ë°©ë²•:** ìœ„ ì¡°ì¹˜ í›„ì—ë„ ì˜¤ë¥˜ê°€ ì§€ì†ë˜ë©´ 'transformers' ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ìµœì‹  ë²„ì „ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”."
    )
    print(f"     >>> pip install --upgrade transformers")
    exit()


# ------------------------------------------------------------------------------
# ì¶”ë¡  í•¨ìˆ˜ ì •ì˜
# ------------------------------------------------------------------------------
def predict_genre(title: str):
    """
    ì£¼ì–´ì§„ ì œëª©ì— ëŒ€í•´ ì¥ë¥´ë¥¼ ì˜ˆì¸¡í•˜ê³  ìƒìœ„ 4ê°œ í´ë˜ìŠ¤ì˜ í™•ë¥ ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    """

    # í† í¬ë‚˜ì´ì§• (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    encoding = tokenizer.encode_plus(
        title,
        max_length=MAX_LEN,
        padding="max_length",
        truncation=True,
        return_tensors="pt",
    )

    # ë””ë°”ì´ìŠ¤ ì´ë™ ë° ì¶”ë¡  (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    input_ids = encoding["input_ids"].to(device)
    attention_mask = encoding["attention_mask"].to(device)

    with torch.no_grad():
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs.logits

    # í™•ë¥  ë³€í™˜
    probs = F.softmax(logits, dim=1).cpu().numpy()[0]

    # í™•ë¥  ë†’ì€ ìˆœì„œëŒ€ë¡œ ì¸ë±ìŠ¤ ì •ë ¬
    ranked_indices = np.argsort(probs)[::-1]

    # ìƒìœ„ 4ê°œ í´ë˜ìŠ¤ ì´ë¦„ê³¼ í™•ë¥ ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ì €ì¥
    top_4_probs = {}
    for i in range(min(4, NUM_CLASSES)):
        idx = ranked_indices[i]
        class_name = LABELS[idx]
        top_4_probs[class_name] = probs[idx]

    # ìµœì¢… ì˜ˆì¸¡ (highest confidence)
    prediction = LABELS[ranked_indices[0]]
    confidence = probs[ranked_indices[0]]

    return prediction, confidence, top_4_probs


# ==============================================================================
# [2] Gradio ë¡œì§ í•¨ìˆ˜ë“¤
# ==============================================================================
def analyze_csv(file_obj):
    if file_obj is None:
        return None

    df = None

    encodings_to_try = ["utf-8", "cp949", "euc-kr"]

    for enc in encodings_to_try:
        try:
            print(f"ğŸ“¡ íŒŒì¼ ì½ê¸° ì‹œë„ (ì¸ì½”ë”©: {enc})...")
            df = pd.read_csv(file_obj.name, encoding=enc)
            print(f"âœ… ì„±ê³µ! (ì¸ì½”ë”©: {enc})")
            break  # ì„±ê³µí–ˆìœ¼ë©´ ë°˜ë³µë¬¸ íƒˆì¶œ
        except Exception as e:
            print(f"âš ï¸ {enc} ë°©ì‹ìœ¼ë¡œ ì½ê¸° ì‹¤íŒ¨.. ë‹¤ìŒ ë°©ì‹ ì‹œë„.")
            continue

    if df is None:
        return pd.DataFrame(
            [{"Error": "âŒ íŒŒì¼ í˜•ì‹ì„ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (UTF-8, CP949 ëª¨ë‘ ì‹¤íŒ¨)"}]
        )

    try:
        # ì»¬ëŸ¼ ì´ë¦„ ì†Œë¬¸ìë¡œ í†µì¼ (title, Title, TITLE -> title)
        df.columns = [str(c).strip().lower() for c in df.columns]

        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        if "title" not in df.columns:
            # í˜¹ì‹œ ì½¤ë§ˆ(,) êµ¬ë¶„ìê°€ ì•„ë‹ˆë¼ ì„¸ë¯¸ì½œë¡ (;) ë“±ìœ¼ë¡œ ëœ CSVì¼ ìˆ˜ë„ ìˆìŒ
            return pd.DataFrame(
                [
                    {
                        "Error": f"CSV íŒŒì¼ í˜•ì‹ì´ ì´ìƒí•©ë‹ˆë‹¤. ì»¬ëŸ¼ì´ í•˜ë‚˜ë¡œ ë­‰ì³¤ë‚˜ìš”? í˜„ì¬ ì¸ì‹ëœ ì»¬ëŸ¼: {list(df.columns)}"
                    }
                ]
            )

        # ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ ì±„ìš°ê¸°
        for col in ["location", "author"]:
            if col not in df.columns:
                df[col] = ""

    except Exception as e:
        return pd.DataFrame([{"Error": f"ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"}])

    processed_rows = []

    # ì˜ˆì¸¡ ë£¨í”„
    for idx, row in df.iterrows():
        title = str(row["title"])

        if not title.strip() or title.lower() == "nan":
            prediction, confidence, top_probs = "ë¯¸ë¶„ë¥˜", 0.0, {}
        else:
            prediction, confidence, top_probs = predict_genre(title)

        conf_display = f"{confidence:.4f}"
        if confidence <= 0.85:
            conf_display = f"<span style='color: red; font-weight: bold;'>{confidence:.4f} (Low)</span>"

        probs_str = ", ".join([f"{k}: {v:.2f}" for k, v in top_probs.items()])

        processed_rows.append(
            {
                "location": row.get("location", ""),
                "title": row["title"],
                "author": row.get("author", ""),
                "subject": prediction,
                "Confidence (Ref)": conf_display,
                "Top Candidates (Ref)": probs_str,
            }
        )

    return pd.DataFrame(processed_rows)


def save_csv(data):
    if data is None or data.empty:
        return None

    output_columns = ["location", "title", "author", "subject"]

    valid_cols = [c for c in output_columns if c in data.columns]
    final_df = data[valid_cols].copy()

    output_filename = "classified_results.csv"
    save_path = os.path.join(os.getcwd(), output_filename)
    final_df.to_csv(save_path, index=False, encoding="utf-8-sig")

    return save_path


# ==============================================================================
# [3] Gradio UI êµ¬ì„± (Blocks ì‚¬ìš©)
# ==============================================================================

with gr.Blocks(title="ë„ì„œ ë¶„ì•¼ ë¶„ë¥˜ê¸°") as demo:
    gr.Markdown("ğŸ“š ë„ì„œ ë¶„ì•¼ ë¶„ë¥˜ ë° ê²€ìˆ˜ ì‹œìŠ¤í…œ ğŸ“š")
    gr.Markdown(
        "CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ AIê°€ ë¶„ì•¼(subject)ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤. confidenceë¥¼ ë³´ê³  ì§ì ‘ ì„ íƒ í›„ ë‹¤ìš´ë¡œë“œ í•˜ì„¸ìš”."
    )
    gr.Markdown(
        "CSV íŒŒì¼ì˜ columnëª…ì€ ë°˜ë“œì‹œ title,author,locationì„ í¬í•¨í•˜ê³  ìˆì–´ì•¼ í•©ë‹ˆë‹¤."
    )

    with gr.Row():
        # [Step 1] íŒŒì¼ ì—…ë¡œë“œ
        file_input = gr.File(
            label="CSV íŒŒì¼ ì—…ë¡œë“œ (location, title, author)", file_types=[".csv"]
        )
        analyze_btn = gr.Button("ğŸ” ë¶„ì„ ì‹œì‘", variant="primary")

    # [Step 2] ê²°ê³¼ í™•ì¸ ë° ìˆ˜ì • (ì¸í„°ë™í‹°ë¸Œ í…Œì´ë¸”)
    gr.Markdown("### ë¶„ì„ ê²°ê³¼ (ë‚´ìš©ì„ í´ë¦­í•˜ì—¬ ì§ì ‘ ìˆ˜ì • ê°€ëŠ¥)")

    # interactive=Trueë¡œ ì„¤ì •í•˜ì—¬ ì‚¬ìš©ìê°€ ì§ì ‘ ì…€ì„ ìˆ˜ì •í•  ìˆ˜ ìˆê²Œ í•¨
    # datatype: ê° ì»¬ëŸ¼ì˜ í˜•ì‹ ì§€ì • ('markdown'ì„ ì“°ë©´ HTML íƒœê·¸ê°€ ë Œë”ë§ë¨ -> ë¹¨ê°„ê¸€ì”¨ ê°€ëŠ¥)
    result_table = gr.Dataframe(
        label="ë¶„ë¥˜ ê²°ê³¼ (subject ì»¬ëŸ¼ì„ í´ë¦­í•˜ì—¬ ìˆ˜ì •í•˜ì„¸ìš”)",
        headers=[
            "location",
            "title",
            "author",
            "subject",
            "Confidence (Ref)",
            "Top Candidates (Ref)",
        ],
        datatype=["str", "str", "str", "str", "markdown", "str"],
        interactive=True,
        wrap=True,
    )

    with gr.Row():
        # [Step 3] ìµœì¢… ë‹¤ìš´ë¡œë“œ
        save_btn = gr.Button("ğŸ’¾ ìˆ˜ì •ì‚¬í•­ ì €ì¥ ë° CSV ìƒì„±", variant="primary")
        output_file = gr.File(label="ìµœì¢… ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", interactive=False)

    # ì´ë²¤íŠ¸ ì—°ê²°
    # 1. ë¶„ì„ ë²„íŠ¼ í´ë¦­ -> analyze_csv ì‹¤í–‰ -> ê²°ê³¼ë¥¼ í‘œì— í‘œì‹œ
    analyze_btn.click(fn=analyze_csv, inputs=file_input, outputs=result_table)

    # 2. ì €ì¥ ë²„íŠ¼ í´ë¦­ -> save_csv ì‹¤í–‰ -> ìµœì¢… íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    save_btn.click(fn=save_csv, inputs=result_table, outputs=output_file)

# ì‹¤í–‰
if __name__ == "__main__":
    demo.launch(share=False)
